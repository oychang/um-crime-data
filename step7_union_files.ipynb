{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/converted_crime_data/Crime_pass5_no_tracts.csv') as f:\n",
    "    data = [r for r in csv.reader(f)]\n",
    "with open('./data/converted_crime_data/Crime_pass6_locations.csv') as f:\n",
    "    locations = [r for r in csv.reader(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 'address'),\n",
       "  (1, 'apt'),\n",
       "  (2, 'case'),\n",
       "  (3, 'primary_offense'),\n",
       "  (4, 'offense_code'),\n",
       "  (5, 'offense'),\n",
       "  (6, 'date_rept'),\n",
       "  (7, 'date_occu'),\n",
       "  (8, 'hour_occu'),\n",
       "  (9, 'date_fnd'),\n",
       "  (10, 'hour_fnd'),\n",
       "  (11, 'fid'),\n",
       "  (12, 'x'),\n",
       "  (13, 'y')],\n",
       " [(0, 'address'), (1, 'fid'), (2, 'building_name'), (3, 'x'), (4, 'y')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(data[0])), list(enumerate(locations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8138, 572, 442)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(set((r[12], r[13]) for r in data[1:])), len(set(r[0] for r in data[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number human readable locations < number locations << number crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1241 THEO DICKINSON DR', 225),\n",
       " ('1239 DICKINSON DR', 291),\n",
       " ('5185 PONCE DE LEON BLVD', 323),\n",
       " ('1239 THEO DICKINSON DR', 331),\n",
       " ('5665 PONCE DE LEON BLVD', 342),\n",
       " ('1101 STANFORD DR', 343),\n",
       " ('1306 STANFORD DR', 354),\n",
       " ('1300 MEMORIAL DR', 358),\n",
       " ('1231 DICKINSON DR', 390),\n",
       " ('1231 THEO DICKINSON DR', 451)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(r[0] for r in data[1:]).items(), key=lambda tup: tup[1])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only use the human readable location (`r[0]`) as a last resort...many crimes are reported at 5665 Ponce de Leon Blvd, the police station but with a far more usable lat, lon value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other frequent addresses \n",
    "\n",
    "http://www.miami.edu/sa/index.php/residential_life/services/mail_packages/\n",
    "\n",
    "* Eaton Residential College\t1211 Dickinson Drive\n",
    "* Mahoney Residential College\t1101 Stanford Drive\n",
    "* Pearson Residential College\t5185 Ponce de Leon Blvd.\n",
    "* Hecht Residential College \t1231 Dickinson Drive\n",
    "* Stanford Residential College\t1239 Dickinson Drive\n",
    "* University Village\t1527 Albenga Avenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `locations.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll join the data in `locations.csv` onto `Crime_pass5*.csv` using the address column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I forgot to check for x, y == 0, 0...null empty string while cleaning up anyway\n",
    "for row in data[1:]:\n",
    "    if row[12] == '' or row[13] == '' or abs(float(row[12])) < 1 or abs(float(row[13])) < 1:\n",
    "        row[12], row[13] = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check if an address uniquely identifies a lat, lon pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SS7': 2, 'University Center': 26}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [(0, 'address'), (1, 'fid'), (2, 'building_name'), (3, 'x'), (4, 'y')]]\n",
    "res = {k: v for k, v in Counter(r[0].strip() for r in locations[1:]).items() if v > 1}\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So no...makes sense for the UC since there are many subdivions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this even a problem in `data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_latlon_missing = [data[0]] + [r for r in data[1:] if r[12] is None]\n",
    "data_latlon_not_missing = [data[0]] + [r for r in data[1:] if r[12] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3936, 4203, 8138, 8138)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_latlon_missing), len(data_latlon_not_missing), len(data_latlon_missing) + len(data_latlon_not_missing) - 1, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(r for r in data_latlon_missing[1:] if r[0] in ('SS7', 'UNIVERSITY CENTER'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's not even a problem! Just exclude those data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitize before join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "rex1 = re.compile(r'\\W+')\n",
    "rex2 = re.compile(r'\\.')\n",
    "clean_addr = lambda s: rex1.sub(' ', rex2.sub(' ', s)).upper().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locations_d = {clean_addr(r[0]): r[1:] for r in locations[1:] if r[0] not in set(['SS7', 'University Center'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(447, 3935)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = [r for r in data_latlon_missing[1:] if r[0] in locations_d]\n",
    "len(matches), len(data_latlon_missing[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_joined_with_location = [data_latlon_missing[0]]\n",
    "for r in data_latlon_missing[1:]:\n",
    "    if r[12] is None and r[0] in locations_d:\n",
    "        info = locations_d[r[0]]\n",
    "        r[11], r[12], r[13] = info[0], info[2], info[3]\n",
    "    data_joined_with_location.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3936"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_joined_with_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geolocate the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "need_to_geocode = [data_joined_with_location[0]] + [r for r in data_joined_with_location[1:] if r[12] is None and r[0] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3482, 310)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_missing_addresses = set(r[0] for r in need_to_geocode[1:])\n",
    "len(need_to_geocode), len(unique_missing_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are only 310 locations without latlon left! Let's see if we have previously cached results, then if necessary call out to the Google geocoder (this requires an API key not included). Since this is my second time around, I'll cheat a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import exists as file_exists\n",
    "geocode_cache_fn = './data/cached_geocode_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if file_exists(geocode_cache_fn):\n",
    "    with open(geocode_cache_fn) as f:\n",
    "        previously_geocoded_data = [r for r in csv.reader(f)]\n",
    "else:\n",
    "    previously_geocoded_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addresses_to_fetch = unique_missing_addresses - set(x[0] for x in previously_geocoded_data[1:])\n",
    "if len(addresses_to_fetch) > 0:\n",
    "    from geopy.geocoders import GoogleV3\n",
    "    from time import sleep\n",
    "    geolocator = GoogleV3(api_key='')\n",
    "    geolocated = {}\n",
    "    failed = []\n",
    "    for loc in addresses_to_fetch:\n",
    "        res = geolocator.geocode(loc + ' CORAL GABLES FL')\n",
    "        if res is None:\n",
    "            print('failed to geolocate {}'.format(loc))\n",
    "            failed.append(loc)\n",
    "        else:\n",
    "            print('got {}'.format(loc))\n",
    "            geolocated[loc] = res\n",
    "        sleep(1 / 10) # API throttling\n",
    "    with open(geocode_cache_fn, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists(geocode_cache_fn)\n",
    "            writer.writerow(['address', 'geolocated_address', 'lat', 'lon', 'altitude'])\n",
    "        for key, value in geolocated.items():\n",
    "            new_row = [key, value.address, value.latitude, value.longitude, value.altitude]\n",
    "            writer.writerow(new_row)\n",
    "            previously_geocoded_data.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Convert and replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ['address', 'geolocated_address', 'lat', 'lon', 'altitude']\n",
    "previously_geocoded_data_d = {r[0]: r[1:] for r in previously_geocoded_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping_gcs = ['address', 'apt',\n",
    "          'case', 'primary_offense',\n",
    "          'offense_code', 'offense',\n",
    "          'date_rept',\n",
    "          'date_occu', 'hour_occu',\n",
    "          'date_fnd', 'hour_fnd',\n",
    "          'fid', 'lat', 'lon']\n",
    "data_gcs = [mapping_gcs]\n",
    "\n",
    "data_spfl = [list(data[0])]\n",
    "for row in data_joined_with_location[1:]:\n",
    "    row = list(row) # make sure we're dealing with a copy and not a pointer\n",
    "    if row[12] == None:\n",
    "        if row[0] != '':\n",
    "            row[1], row[5] = clean_addr(row[1]), clean_addr(row[5]) \n",
    "            info = previously_geocoded_data_d[row[0]]\n",
    "            row[12], row[13] = info[1], info[2]\n",
    "            data_gcs.append(row)\n",
    "    else:\n",
    "        row[1], row[5] = clean_addr(row[1]), clean_addr(row[5])\n",
    "        data_spfl.append(row)\n",
    "for row in data_latlon_not_missing[1:]:\n",
    "    row = list(row) # make sure we're dealing with a copy and not a pointer\n",
    "    row[1], row[5] = clean_addr(row[1]), clean_addr(row[5]) \n",
    "    data_spfl.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove manually seen outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_spfl_clean = [data_spfl[0]]\n",
    "for row in data_spfl[1:]:\n",
    "    if float(row[12]) < 89380:\n",
    "        continue\n",
    "    data_spfl_clean.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/converted_crime_data/Crime_pass7_latlon.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in data_gcs:\n",
    "        writer.writerow(row)\n",
    "with open('./data/converted_crime_data/Crime_pass7_spfl.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in data_spfl_clean:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
